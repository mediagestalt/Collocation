{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collocational Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"You shall know a word by the company it keeps!\" These are the oft-quoted words of the linguist J.R. Firth in describing the meaning and spirit of collocational analysis. Collocation is a linguistic term for co-occuring. While most words have the possibility of co-occuring with most other words at some point in the English language, when there is a significant statistical relationship between two regularly co-occuring words, we can refer to these as collocates. One of the first, and most cited examples of collocational analysis concerns the words `strong` and `powerful`. While both words mean arguably the same thing, it is statistically more common to see the word `strong` co-occur with the word `tea`. Native speakers of English can immediately recognize the familiarity of `strong tea` as opposed to `powerful tea`, even though the two phrases both make sense in their own way (see Halliday, 1966 for more of this discussion). Interestingly, the same associations do not occur with the phrases `strong men` and `powerful men`, although in these instances, both phrases take on slightly different meanings.\n",
    "\n",
    "These examples highlight the belief of Firthian linguists that the meaning of a word is not confined to the word itself, but in the associations that words have with other co-occuring words. Statistically significant collocates need not be adjacent, just proximal. The patterns of the words in a text, rather than the individual words themselves, have complex, relational units of meaning that allow us to ask questions about the use of lanugage in specific discourses.\n",
    "\n",
    "In this exercise we will determine the statistical significance of the words that most often co-occur with `privacy` in an attempt to better understand the meaning of the word as it is used in the Hansard Corpus. We will count the actual frequency of the co-occurence, as well as use a number of different statistical tests of probability. These tests will be conducted first on one file from the corpus, then on the entire corpus itself. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Collocational analysis on one file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section will determine the statistically significant collocates that accompany the word `privacy` in the file for 2015. Testing file-by-file allows us to track the diachronic (time-based) change and use of the words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we'll begin by calling on all the <span style=\"cursor:help;\" title=\"a set of instructions that performs a specific task\"><b>functions</b></span> we will need. Remember that the first few sentences are calling on pre-installed <i>Python</i> <span style=\"cursor:help;\" title=\"packages of functions and code that serve specific purposes\"><b>modules</b></span>, and anything with a `def` at the beginning is a custom function built specifically for these exercises. The text in red describes the purpose of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This is where the modules are imported\n",
    "import csv\n",
    "import sys\n",
    "import codecs\n",
    "import nltk\n",
    "import nltk.collocations\n",
    "import collections\n",
    "import statistics\n",
    "from nltk.metrics.spearman import *\n",
    "from nltk.collocations import *\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from os import listdir\n",
    "from os.path import splitext\n",
    "from os.path import basename\n",
    "from tabulate import tabulate\n",
    "\n",
    "# These functions iterate through the directory and create a list of filenames\n",
    "\n",
    "def list_textfiles(directory):\n",
    "    \"Return a list of filenames ending in '.txt'\"\n",
    "    textfiles = []\n",
    "    for filename in listdir(directory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            textfiles.append(directory + \"/\" + filename)\n",
    "    return textfiles\n",
    "\n",
    "\n",
    "def remove_ext(filename):\n",
    "    \"Removes the file extension, such as .txt\"\n",
    "    name, extension = splitext(filename)\n",
    "    return name\n",
    "\n",
    "\n",
    "def remove_dir(filepath):\n",
    "    \"Removes the path from the file name\"\n",
    "    name = basename(filepath)\n",
    "    return name\n",
    "\n",
    "\n",
    "def get_filename(filepath):\n",
    "    \"Removes the path and file extension from the file name\"\n",
    "    filename = remove_ext(filepath)\n",
    "    name = remove_dir(filename)\n",
    "    return name\n",
    "\n",
    "# This function works on the contents of the files\n",
    "\n",
    "def read_file(filename):\n",
    "    \"Read the contents of FILENAME and return as a string.\"\n",
    "    infile = codecs.open(filename, 'r', 'utf-8')\n",
    "    contents = infile.read()\n",
    "    infile.close()\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collocational analysis is a frequency-based technique that uses word counts to determine significance. One of the problems with counting word frequencies, as we have seen in other sections, is that the most frequently occuring words in English are function words, like `the`, `of`, and `and`. For this reason, it is neccessary to remove these words in order to obtain meaningful results. In text analysis, these high frequency words are compiled into lists called `stopwords`. While standard stopword lists are provided by the `NLTK` module, for the Hansard Corpus it was necessary to remove other kinds of words, like proper nouns (names and place names), and other words common to parliamentary proceedings (like Prime Minister, Speaker, etc.). These words, along with the standard stopwords, can be seen below.\n",
    "\n",
    "Here, we use our `read_file` function to read in a text file of custom stopwords, assigning the variable `customStopwords`. We tokenize the list using the `split` function and then create a variable called `hansardStopwords` that incorporates the `NLTK` stopword list, and adding the words from `customStopwords` if they don't already occur in the `NLTK` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stopwords = read_file('HansardStopwords.txt')\n",
    "customStopwords = stopwords.split()\n",
    "\n",
    "#default stopwords with custom words added\n",
    "hansardStopwords = nltk.corpus.stopwords.words('english') \n",
    "hansardStopwords += customStopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 'a', 'abbott', 'abitibi', 'ablonczy', 'about', 'above', 'acadie', 'accordance', 'according', 'act', 'acting', 'adam', 'addington', 'adler', 'after', 'again', 'against', 'agencies', 'aglukkaq', 'agriculture', 'alan', 'albas', 'albrecht', 'alexandrine', 'alfred', 'algoma', 'alice', 'all', 'allen', 'allison', 'also', 'am', 'ambler', 'ambrose', 'an', 'ancaster', 'and', 'anders', 'anderson', 'andre', 'andrew', 'andrews', 'angus', 'angus:', 'anita', 'ann', 'anthony', 'any', 'arctic', 'are', 'arent', 'argenteuil', 'armstrong', 'art', 'arthur', 'as', 'ashfield', 'ashton', 'aspin', 'asselin', 'assistant', 'at', 'atamanenko', 'aubin', 'aurora', 'avalon', 'aylmer', 'bachand', 'back', 'bagnell', 'baie', 'bains', 'baird', 'barbe', 'barlow', 'barlow', 'barrie', 'barry', 'basques', 'bateman', 'bathurst', 'bay', 'be', 'beauce', 'beaudin', 'because', 'been', 'before', 'being', 'belanger', 'bellavance', 'bellechasse', 'below', 'belt', 'bennett', 'benoit', 'ber', 'bernard', 'bernier', 'betty', 'between', 'bevington', 'bezan', 'biggar', 'bigras', 'bill', 'blackburn', 'blainville', 'blais', 'blake', 'blanchette', 'blaney', 'bloc', 'block', 'board', 'bob', 'bonavista', 'boniface', 'bonsant', 'borduas', 'borg', 'boshcoff', 'both', 'bouchard', 'boucher', 'boughen', 'bourassa', 'bourgeois', 'boutin', 'bq', 'bradley', 'braid', 'brampton', 'breitkreuz', 'breton', 'brian', 'brison', 'british', 'brock', 'brown', 'bruce', 'bruinooge', 'brunelle', 'bruno', 'bryan', 'bryon', 'bulkley', 'bureau', 'burin', 'burnaby', 'but', 'by', 'byrne', 'cadman', 'calandra', 'calgary', 'calkins', 'cambridge', 'can', 'canada', 'canadian', 'canadians', 'cannan', 'cannis', 'cannon', 'cannot', 'canso', 'cant', 'cape', 'cardin', 'cariboo', 'carleton', 'carmichael', 'carol', 'carole', 'caron', 'carrie', 'carrier', 'cartier', 'cash', 'casson', 'catharines', 'cathy', 'cavoukian', 'central', 'centre', 'chambly', 'champlain', 'chantal', 'charlevoix', 'charlie', 'charlottetown', 'charlton', 'charmaine', 'châteauguay', 'chaudiere', 'chicoutimi', 'chief', 'chisu', 'chong', 'chow', 'christian', 'christiane', 'christopherson', 'chuck', 'chungsen', 'churchill', 'chutes', 'clarke', 'claude', 'clement', 'coady', 'coast', 'coderre', 'colchester', 'cole', 'colin', 'colleague', 'columbia', 'comartin', 'commission', 'commissioner', 'commissioners', 'committee', 'commons', 'communities', 'conestoga', 'conservative', 'conservatives', 'constant', 'cooksville', 'coquitlam', 'corneliu', 'costas', 'cote', 'cotler', 'could', 'couldnt', 'country', 'cpc', 'craig', 'creek', 'crockatt', 'crombie', 'crowder', 'crowfoot', 'cullen', 'cumberland', 'cummins', 'cuzner', 'cyr', 'dame', 'damours', 'dan', 'danforth', 'daniel', 'dartmouth', 'daryl', 'dauphin', 'dave', 'davenport', 'david', 'davidson', 'davies', 'day', 'de', 'dean', 'debate', 'debellefeuille', 'dechert', 'deepak', 'del', 'delta', 'demers', 'democratic', 'denis', 'denise', 'dennis', 'des', 'desnoyers', 'devolin', 'dewar', 'dhaliwal', 'dhalla', 'diane', 'did', 'didnt', 'dieppe', 'dion', 'do', 'does', 'doesnt', 'doing', 'dollard', 'don', 'donnelly', 'dont', 'dore', 'dorion', 'dosanjh', 'douglas', 'down', 'doyle', 'dreeshen', 'drummond', 'dryden', 'duceppe', 'dufour', 'duncan', 'dundas', 'during', 'dykstra', 'each', 'east', 'easter', 'eastern', 'ed', 'edmonton', 'edward', 'eeyou', 'eglinski', 'eglinton', 'elgin', 'english', 'epp', 'esquimalt', 'essex', 'etobicoke', 'eve', 'even', 'eyking', 'fabian', 'faille', 'falls', 'fanshawe', 'fantino', 'fast', 'federal', 'few', 'finance', 'findlay', 'finley', 'first', 'fjord', 'flaherty', 'flamborough', 'fletcher', 'folco', 'foote', 'for', 'forward', 'francis', 'freeman', 'from', 'frontenac', 'fry', 'fundy', 'further', 'gagnon', 'galipeau', 'gallant', 'gander', 'garneau', 'garrison', 'garry', 'gatineau', 'gaudet', 'genereux', 'geoff', 'george', 'georges', 'gerald', 'gerard', 'get', 'gill', 'gilles', 'glen', 'glengarry', 'glover', 'go', 'godfrey', 'godin', 'goguen', 'going', 'goldring', 'goodale', 'goodyear', 'gordon', 'gourde', 'government', 'grâce', 'grand', 'gravelle', 'greg', 'grenville', 'grewal', 'groguhe', 'guarnieri', 'guay', 'guelph', 'guergis', 'guildwood', 'guimond', 'guy', 'had', 'hadnt', 'haliburton', 'halifax', 'hall', 'hamilton', 'hanger', 'hants', 'harbour', 'harold', 'harper', 'harris', 'harvey', 'has', 'hasnt', 'hassainia', 'hastings', 'hat', 'haute', 'have', 'havent', 'having', 'hawn', 'hayes', 'he', 'hearn', 'hebert', 'hed', 'hedy', 'hell', 'her', 'here', 'heres', 'heritage', 'hers', 'herself', 'hes', 'hiebert', 'hill', 'hillyer', 'him', 'himself', 'hinton', 'his', 'hoback', 'hochelaga', 'hoeppner', 'holder', 'holland', 'hon', 'house', 'how', 'however', 'hows', 'hsu', 'hubert', 'hughes', 'hull', 'humber', 'hyer', 'i', 'id', 'if', 'ignatieff', 'iles', 'îles', 'ill', 'im', 'in', 'including', 'ind', 'infrastructure', 'interim', 'interlake', 'into', 'irene', 'irwin', 'is', 'island', 'islands', 'isnt', 'it', 'its', 'its', 'itself', 'ive', 'jack', 'jacques', 'jaffer', 'james', 'jay', 'jean', 'jeanne', 'jeff', 'jennifer', 'jennings', 'jim', 'jinny', 'joan', 'joe', 'jogindera', 'john', 'johns', 'joliette', 'jonathan', 'jones', 'josee', 'joseph', 'joy', 'joyce', 'juan', 'judy', 'julian', 'just', 'justin', 'kamp', 'kania', 'kapuskasing', 'karen', 'karygiannis', 'kawartha', 'keddy', 'keith', 'kelly', 'kelowna', 'ken', 'kennedy', 'kenney', 'kenora', 'kent', 'kerr', 'kesteren', 'kevin', 'kildonan', 'kings', 'kingston', 'kingsway', 'kirsty', 'kitchener', 'know', 'komarnicki', 'kramp', 'kyle', 'la', 'labelle', 'labrador', 'lac', 'lachine', 'laforest', 'laframboise', 'lake', 'lakes', 'lalonde', 'lambert', 'lamothe', 'lamoureux', 'lanark', 'last', 'latendresse', 'laurent', 'laurentides', 'laurie', 'laurier', 'laurin', 'lauzon', 'laval', 'lavallee', 'lavar', 'lawrence', 'layton', 'le', 'leader', 'lebel', 'leblanc', 'leduc', 'lee', 'leeds', 'leef', 'lefebvre', 'legislative', 'lemay', 'lemieux', 'lennox', 'leon', 'leona', 'les', 'leslie', 'lessard', 'lets', 'letter', 'leung', 'levesque', 'levis', 'lib', 'libby', 'liberal', 'like', 'lile', 'linda', 'lise', 'liu', 'lizon', 'loan', 'lobb', 'london', 'longueuil', 'lotbiniere', 'louis', 'loyola', 'luc', 'lukiwski', 'lunn', 'lunney', 'lysane', 'macaulay', 'mackay', 'mackenzie', 'mactaquac', 'made', 'make', 'malcolm', 'malhi', 'malo', 'maloway', 'malpeque', 'manicouagan', 'manitoulin', 'manning', 'many', 'maple', 'marc', 'margarets', 'marie', 'mario', 'marjolaine', 'mark', 'markham', 'marlene', 'marquette', 'marston', 'martin', 'masse', 'mastro', 'mathieu', 'mathyssen', 'maurice', 'mauril', 'mayes', 'mccallum', 'mccoleman', 'mcguinty', 'mckay', 'mcleod', 'mcteague', 'me', 'meadows', 'medicine', 'megan', 'meili', 'member', 'members', 'menard', 'mendes', 'menegakis', 'menzies', 'merrifield', 'michael', 'middlesex', 'mike', 'mille', 'miller', 'mills', 'minister', 'minna', 'mirabel', 'mission', 'mississauga', 'mississippi', 'moncton', 'monte', 'montmorency', 'moody', 'moore', 'more', 'morin', 'most', 'motion', 'mount', 'mountain', 'mourani', 'mr', 'ms', 'mulcair', 'murphy', 'murray', 'musquodoboit', 'must', 'mustnt', 'my', 'myron', 'myself', 'nadeau', 'nathan', 'national', 'navdeep', 'ndp', 'need', 'neigette', 'nepean', 'neville', 'new', 'newfoundland', 'newmarket', 'newton', 'nicholson', 'nickel', 'nicolas', 'nicole', 'niki', 'nipissing', 'no', 'nor', 'nord', 'norlock', 'norman', 'north', 'northumberland', 'not', 'notre', 'nova', 'now', 'nunavik', 'oak', 'obhrai', 'oconnor', 'oda', 'of', 'off', 'office', 'oliphant', 'on', 'once', 'one', 'oneill', 'only', 'opitz', 'or', 'orleans', 'oshawa', 'other', 'ottawa', 'ouellet', 'ought', 'our', 'ours', 'ourselves', 'out', 'outremont', 'over', 'own', 'oxford', 'pacetti', 'paille', 'palliser', 'papineau', 'paquette', 'paradis', 'park', 'parliament', 'parliamentary', 'parm', 'part', 'party', 'pascal', 'pat', 'patrick', 'patriotes', 'patry', 'paul', 'pauline', 'payne', 'peace', 'pearl', 'pearson', 'pellan', 'people', 'perkins', 'peter', 'peterborough', 'petit', 'phil', 'picard', 'pierre', 'pierrefonds', 'pitt', 'plamondon', 'poilievre', 'pointe', 'pomerleau', 'pontiac', 'port', 'portneuf', 'prentice', 'prescott', 'president', 'preston', 'prime', 'prince', 'proceedings', 'program', 'proulx', 'public', 'put', 'quadra', 'quappelle', 'quebec', 'question', 'quinte', 'rae', 'rafferty', 'rahim', 'rainy', 'raitt', 'rajotte', 'ralph', 'randall', 'random', 'rankin', 'ratansi', 'rathgeber', 'ravignat', 'ray', 'redman', 'reform', 'regan', 'regina', 'reid', 'repentigny', 'richard', 'richards', 'richardson', 'richmond', 'rick', 'rickford', 'ridge', 'ridges', 'rimouski', 'ritz', 'river', 'riverview', 'riviere', 'rivieres', 'rob', 'robert', 'rod', 'rodger', 'rodney', 'rodriguez', 'rona', 'rosane', 'rosetown', 'rota', 'roxanne', 'royal', 'ruby', 'russell', 'ryan', 's', 'sackville', 'sadia', 'said', 'saint', 'sainte', 'same', 'sana', 'saskatoon', 'sault', 'savage', 'savoie', 'saxton', 'say', 'scarborough', 'scarpaleggia', 'scheer', 'schellenberger', 'scott', 'sea', 'secretary', 'see', 'seeback', 'selkirk', 'sgro', 'shant', 'shawn', 'she', 'shea', 'shed', 'shell', 'shelly', 'sherbrooke', 'sherwood', 'shes', 'shipley', 'shore', 'shory', 'should', 'shouldnt', 'siksay', 'silva', 'simcoe', 'simms', 'sims', 'simson', 'siobhan', 'skeena', 'sky', 'smith', 'so', 'solberg', 'some', 'sopuck', 'sorenson', 'soulanges', 'south', 'southeast', 'southwest', 'speaker', 'st', 'stanton', 'stated', 'statutes', 'ste', 'stella', 'stephen', 'steven', 'stoddart', 'stoffer', 'stoney', 'storseth', 'strahl', 'strathcona', 'such', 'sudbury', 'sukh', 'sunshine', 'support', 'susan', 'swan', 'sweet', 'sydney', 'sylvie', 'szabo', 'take', 'ted', 'temiscamingue', 'temiscouata', 'terrebonne', 'than', 'that', 'thats', 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'theres', 'therrien', 'these', 'they', 'theyd', 'theyll', 'theyre', 'theyve', 'thi', 'thibeault', 'thierry', 'think', 'this', 'thomas', 'thompson', 'those', 'though', 'through', 'thunder', 'tilson', 'tim', 'time', 'timiskaming', 'timmins', 'to', 'tobique', 'today', 'todd', 'toews', 'told', 'tom', 'tonks', 'tony', 'too', 'toronto', 'translation', 'treasury', 'tremblay', 'trois', 'trost', 'trottier', 'trudeau', 'truppe', 'tweed', 'two', 'ujjal', 'under', 'unionville', 'until', 'up', 'uppal', 'us', 'valcourt', 'valeriote', 'valley', 'van', 'vancouver', 'vaudreuil', 'vaughan', 'vellacott', 'vercheres', 'verner', 'verte', 'very', 'victoria', 'ville', 'vincent', 'volpe', 'wallace', 'want', 'warawa', 'warkentin', 'was', 'wascana', 'wasnt', 'watson', 'way', 'wayne', 'we', 'wed', 'well', 'welland', 'were', 'were', 'werent', 'west', 'westdale', 'western', 'westlock', 'westminster', 'westmount', 'weston', 'westwood', 'weve', 'what', 'whats', 'when', 'whens', 'where', 'wheres', 'which', 'while', 'whip', 'who', 'whom', 'whos', 'why', 'whys', 'wilfert', 'wilks', 'will', 'williamson', 'willowdale', 'windsor', 'winnipeg', 'with', 'wladyslaw', 'wong', 'wont', 'woodworth', 'would', 'wouldnt', 'wrzesnewskyj', 'year', 'years', 'yelich', 'yellowhead', 'york', 'you', 'youd', 'youll', 'young', 'your', 'youre', 'yours', 'yourself', 'yourselves', 'youve', 'yukon', 'yves', 'yvon', 'yvonne', 'zarac', 'zimmer']\n"
     ]
    }
   ],
   "source": [
    "print(hansardStopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now, we use `read_file` to load the contents of the file for 2015. For consistency and to avoid file duplication, we're always reading the files from the same directory. Even though it was used for other sections, the data is the same. We read the contents of the text file, then remove the case and punctuation from the text, split the words into a list of tokens, and assign the words in each file to a list with the variable name `text`. What's new here, compared to other sections, is the additional removal of stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# opens, reads, and tokenizes the file\n",
    "text = read_file('data/2015.txt')\n",
    "words = text.split()\n",
    "clean = [w.lower() for w in words if w.isalpha()]\n",
    "# removes stopwords\n",
    "text = [w for w in clean if w not in hansardStopwords]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another type of processing required for the generation of accurate collocational statistics is called lemmatization. In linguistics, a lemma is the grammatical base or stem of a word. For example, the word `protect` is the lemma of the verbs `protecting` and `protected`, while `ethic` is the lemma of the noun `ethics`. When we lemmatize a text, we are removing the grammatical inflections of the word forms (like `ing` or `ed`). The purpose of lemmatization for the Hansard Corpus is to obtain more accurate statistics for collocation by avoiding multiple entries for similar but different word forms (like protecting, protected, and protect). For the purpose of this text analysis, I have decided to lemmatize only the nouns and verbs in the Hansard Corpus, as the word `privacy` is not easily modified by adjectives (or at all by adverbs). \n",
    "\n",
    "The lemmatizer I have used for this project was developed by Princeton and is called <a href=\"http://wordnetweb.princeton.edu/perl/webwn\" target=\"_blank\">WordNet</a>. Lemmas and their grammatical inflections can be searched using their web interface. \n",
    "\n",
    "In the code below, I load the WordNetLemmatizer (another function included in the `NLTK` module) into the variable `wnl`. Then, I iterate through the text, first lematizing the verbs (shown as `v`), then the nouns (shown as `n`). Unfortunately, the WordNet function only takes one argument, so this code requires two pass-throughs of the text. I'm sure there is a more elegant way to construct this code, though I've not found it yet. This is another reason why I've decided only to lemmatize verbs and nouns, rather than including adjectives and adverbs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# creates a variable for the lemmatizing function\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "# lemmatizes all of the verbs\n",
    "lemm = []\n",
    "for word in text:\n",
    "    lemm.append(wnl.lemmatize(word, 'v'))\n",
    "\n",
    "# lemmatizes all of the nouns \n",
    "lems = []\n",
    "for word in lemm:\n",
    "    lems.append(wnl.lemmatize(word, 'n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to make sure that the lemmatizer did something. Since we've only lemmatized for nouns and verbs, we check that here against the unlemmatized corpus, where `text` has not been lemmatized and `lems` has. Below we see that noun `ethics` appears <u>156 times</u> in the `text` variable and <u>0 times</u> in the `lems` variable. But the lemma for `ethics`: `ethic`, remains in the `lems` variable for a frequency of <u>161 times</u>. Similar values are repeated for the verb and variations of `protect`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOUNS\n",
      "ethics: 156\n",
      "ethics: 0\n",
      "ethic: 161\n",
      "\n",
      "\n",
      "VERBS\n",
      "protecting: 737\n",
      "protecting: 0\n",
      "protected: 268\n",
      "protected: 0\n",
      "protect: 3401\n"
     ]
    }
   ],
   "source": [
    "print('NOUNS')\n",
    "print('ethics:', text.count('ethics'))\n",
    "print('ethics:', lems.count('ethics'))\n",
    "print('ethic:', lems.count('ethic'))\n",
    "print('\\n')\n",
    "print('VERBS')\n",
    "print('protecting:', text.count('protecting'))\n",
    "print('protecting:', lems.count('protecting'))\n",
    "print('protected:', text.count('protected'))\n",
    "print('protected:', lems.count('protected'))\n",
    "print('protect:', lems.count('protect'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we check that the lemmatizer hasn't been over-zealous by determining the frequency for `privacy` before and after the lemmatizing function. The frequencies are the same, meaning we've not lost anything in the lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "privacy: 806\n",
      "privacy: 806\n"
     ]
    }
   ],
   "source": [
    "print('privacy:', text.count('privacy'))\n",
    "print('privacy:', lems.count('privacy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1.1: Unfocused Bigram Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's clarify some of the words we will be using in the rest of this exercise:\n",
    "- `ngram` = catch-all term for multiple word occurences\n",
    "- `bigram` = word pairs\n",
    "- `trigram` = three-word phrases\n",
    "\n",
    "After the stopwords have been removed and the nouns and verbs lemmatized, we are ready to determine statistics for co-occuring words, or collocates. Any collocational test requires four pieces of data: the length of the text in which the words appear, the number of times the words both seperately appear in the text, and the number of times the words occur together.\n",
    "\n",
    "Before we focus our search on the word `privacy`, we will determine the 10 most commonly occuring bigrams (based on frequency) in the 2015 Hansard Corpus. \n",
    "\n",
    "In this code we assign the `lems` variable to `colText` by adding the `nltk.Text` functionality. We can then use the `NLTK` function `collocations` to determine (in this case) the 10 most common bigrams. Changing the number in the brackets will change the number of results returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small business; child care; supreme court; criminal code; action plan;\n",
      "employment social; health care; foreign affair; social development;\n",
      "spinal cord\n"
     ]
    }
   ],
   "source": [
    "# prints the 10 most common bigrams\n",
    "colText = nltk.Text(lems)\n",
    "colText.collocations(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, I ran an earlier test that shows the 10 most common bigrams without the stopwords removed. Duplicating this test only requires that stopwords not be removed as the text is being tokenized and cleaned. We can see that there is a clear difference in the types of results returned with and without stopwords applied. The list of words appearing above is much more interesting in terms of discourse analysis, when functional parliamentary phrases like Prime Minister and Parliamentary Secretary have been removed."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "prime minister; would like; parliamentary secretary; first nation;\n",
    "public safety; british columbia; act speaker; small business; ontario\n",
    "cpc; new democrat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a piece of code that shows how the ngram function works. It goes word by word through the text, pairing each word with the one that came before. That's why the last word in the first word pair becomes the first in the next word pair.\n",
    "\n",
    "We assign our `colText` variable to the `colBigrams` variable by specifiying that we want to make a list of ngrams containing 2 words. We could obtain trigrams by changing the 2 in the first line of code to a 3. Then, in the second line of code, we display the first 5 results of the `colBigrams` variable with :5. We could display the first 10 by changing the number in the square brackets to :10, or show the top 10 results again by removing the colon. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('official', 'report'),\n",
       " ('report', 'debate'),\n",
       " ('debate', 'volume'),\n",
       " ('volume', 'number'),\n",
       " ('number', 'session')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creates a list of bigrams (ngrams of 2), printing the first 5\n",
    "colBigrams = list(nltk.ngrams(colText, 2)) \n",
    "colBigrams[:5] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will check to make sure we've the bigram function has gone through and counted the entire text. Having one less ngram is correct because of the way in which the ngrams are generated word-by-word in the test above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: 1361982\n",
      "Number of bigrams: 1361981\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of words:\", len(lems))\n",
    "print(\"Number of bigrams:\", len(colBigrams))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1.2: Focused Bigram Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will focus our search on bigrams that contain the word `privacy`. First, we'll load the bigram tests from the `NLTK` module, then, we will create a filter that only searches for bigrams containing `privacy`. To search for bigrams containing other words, the word `privacy` in the second line of code can be changed to something else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# loads bigram code from NLTK\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "\n",
    "# ngrams with 'privacy' as a member\n",
    "privacy_filter = lambda *w: 'privacy' not in w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will load our lemmatized corpus into the bigram collocation finder, apply a frequency filter that only considers bigrams that appear four or more times, and then apply our privacy filter to the results. The variable `finder` now contains a list of all the bigrams containing `privacy` that occur four or more times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# bigrams\n",
    "finder = BigramCollocationFinder.from_words(lems)\n",
    "# only bigrams that appear 4+ times\n",
    "finder.apply_freq_filter(4)\n",
    "# only bigrams that contain 'privacy'\n",
    "finder.apply_ngram_filter(privacy_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Distribution\n",
    "\n",
    "Before I describe the statistical tests that we will use to determine the collocates for `privacy`, it is important to briefly discuss distribution. The chart below maps the distribution of the top 25 terms in the 2015 file.  \n",
    "\n",
    "This is important because some of the tests assume a normal distribution of words in the text. A normal distribution means that the majority of the words occur a majority of the time; it is represented in statistics as a bell curve. This means that 68% of the words would occur within one standard deviation of the mean (or average frequency of each word in the text), 95% within two standard deviations, and 99.7 within three standard deviations. \n",
    "\n",
    "What this means, is that tests that assume a normal distribution will work, but have inaccurate statistics to back them up. I've chosen to describe all of the collocational tests here as a matter of instruction and description, but it's important to understand the tests and what they assume before making research claims based on their results.\n",
    "\n",
    "The code below calls on the `NLTK` function `FreqDist`. The function calculates the frequency of all the words in the variable and charts them in order from highest to lowest. Here I've only requested the first 25, though more or less can be displayed by changing the number in the brackets. Additionally, in order to have the chart displayed inline (and not as a popup), I've called the <i>magic</i> function `matplotlib inline`. <i>iPython</i> magic functions are identifable by the <b>%</b> symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAE2CAYAAACUQW4dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nI2FmZoXcSJiZWaH/AMUyippeGBRtAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13f88f860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "fd = nltk.FreqDist(colText)\n",
    "fd.plot(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the chart above, `work` is the highest frequency word in our lemmatized corpus with stopwords applied, followed by `right`. The word `privacy` does not even occur in the list. The code below calculates the frequency and percentage of times these words occur in the text. While `work` makes up 0.56% of the total words in the text, `privacy` accounts for only 0.06%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "privacy: 806 times or 0.06%\n",
      "right: 5632 times or 0.41%\n",
      "work: 7588 times or 0.56%\n"
     ]
    }
   ],
   "source": [
    "print('privacy:',fd['privacy'], 'times or','{:.2%}'.format(float(colText.count(\"privacy\"))/(len(colText))))\n",
    "print('right:',fd['right'], 'times or','{:.2%}'.format(float(colText.count(\"right\"))/(len(colText))))\n",
    "print('work:',fd['work'], 'times or','{:.2%}'.format(float(colText.count(\"work\")/(len(colText)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the mean, and standard deviation, we must count the frequency of all the words in the text and append those values to a list. Since the numbers in the list will actually be represented as text (not as integers), we must add an extra line of code to map those values so they can be used mathematically, calling on the `map` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fdnums = []\n",
    "for sample in fd:\n",
    "    fdnums.append(fd[sample])\n",
    "numlist = list(map(int, fdnums))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of unique words: 18912\n",
      "Total of words that appear only once: 5847\n",
      "Percentage of words that appear only once: 30.92%\n"
     ]
    }
   ],
   "source": [
    "print(\"Total of unique words:\", len(numlist))\n",
    "print(\"Total of words that appear only once:\", len(fd.hapaxes()))\n",
    "print(\"Percentage of words that appear only once:\",'{:.2%}'.format(len(fd.hapaxes())/len(numlist)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have our numbers in a list, as the variable `numlist`, we can use the built in `statistics` library for our calculations. Below we've calculated the mean, standard deviation, and the variance. \n",
    "\n",
    "These numbers prove that the numerical data has a non-normal distribution. The mean is relatively low, compared to the highest frequency word, `work`, which appears a total of <u>7588</u> times. \n",
    "\n",
    "The low mean is due to the high number of low frequency words; there are <u>5847</u> words that appear only once, totalling 30% of the unique words in the entire set. The standard deviation is higher than the mean, which predicts a high variance of numbers in the set, something that is proven by the variance calculation. A large variance shows that the numbers in the set are far apart from the mean, and each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 72.02\n",
      "Standard Deviation: 300.24\n",
      "Variance: 90144.28\n"
     ]
    }
   ],
   "source": [
    "datamean = statistics.mean(numlist)\n",
    "print(\"Mean:\", '{:.2f}'.format(statistics.mean(numlist)))\n",
    "print(\"Standard Deviation:\", '{:.2f}'.format(statistics.pstdev(numlist,datamean)))\n",
    "print(\"Variance:\", '{:.2f}'.format(statistics.pvariance(numlist,datamean)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Raw Frequency\n",
    "The frequency calculations determine both the actual number of occurences of the bigram in the corpus as well as the number of times the bigram occurs relative to the text as a whole (expressed as a percentage).\n",
    "\n",
    "##### Student's-T \n",
    "The Student's T-Score, also called the T-Score, measures the <b>confidence</b> of a claim of collocation and assigns a score based on that certainty. It is computed by subtracting the expected frequency of the bigram by the observed frequency of the bigram, and then dividing the result by the standard deviation which is calculated based on the overall size of the corpus. \n",
    "\n",
    "The benefit of using the T-Score is that it considers the evidence for collocates based on the overall amount of evidence provided by the size of the corpus. This differs from the PMI score (described below) which only considers strength based on relative frequencies. The drawbacks to the T-Score include its reliance on a normal distribution (due to the incorporation of standard deviation in the calculation), as well as its dependence on the overall size of the corpus. T-scores can't be compared across corpora of different sizes.\n",
    "\n",
    "##### Pointwise Mutual Information \n",
    "The Pointwise Mutual Information Score (known as PMI or MI) measures the <b>strength</b> of a collocation and assigns it a score. It is a probability-based calculation that compares the number of actual bigrams to the expected number of bigrams based on the relative frequency counts of the words. The test compares the expected figure to the observed figure, converting the difference to a number indicating the strength of the collocation.\n",
    "\n",
    "The benefit of using PMI is that the value of the score is not dependent on the overall size of the corpus, meaning that PMI scores can be compared across corpora of different sizes, unlike the T-score (described above).\n",
    "The drawback to the PMI is that it tends to give high scores to low frequency words when they occur most often in the proximity another word.\n",
    "\n",
    "##### Chi-square \n",
    "The Chi-square (or x<sup>2</sup>) measures the observed and expected frequencies of bigrams and assigns a score based on the amount of difference between the two using the standard deviation. The Chi-square is another test that relies on a normal distribution.\n",
    "\n",
    "The Chi-square shares the benefit of the T-score in taking into account the overall size of the corpus. The drawback of the Chi-square is that it doesn't do well with sparse data. This means that low-frequency (but significant) bigrams may not be represented very well, unlike the scores assigned by the PMI.\n",
    "\n",
    "##### Log-Likelihood Ratio\n",
    "The Log-likelihood ratio calculates the size and significance between the observed and expected frequencies of bigrams and assigns a score based on the result, taking into account the overall size of the corpus. The larger the difference between the observed and expected, the higher the score, and the more statistically significant the collocate is. \n",
    "\n",
    "The Log-likelihood ratio is my preferred test for collocates because it does not rely on a normal distribution, and for this reason, it can account for sparse or low frequency bigrams (unlike the Chi-square). But unlike the PMI, it does not over-represent low frequency bigrams with inflated scores, as the test is only reporting how much more likely it is that the frequencies are different than they are the same. The drawback to the Log-likelihood ratio, much like the t-score, is that it cannot be used to compare scores across corpora.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code filters the results of the focused bigram search based on the statistical tests as described above, assigning the results to a new variable based on the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filter results based on statistical test\n",
    "\n",
    "# calulates the raw frequency as an actual number and percentage of total words\n",
    "act = finder.ngram_fd.items()\n",
    "raw = finder.score_ngrams(bigram_measures.raw_freq)\n",
    "# student's - t score\n",
    "tm = finder.score_ngrams(bigram_measures.student_t)\n",
    "# pointwise mutual information score\n",
    "pm = finder.score_ngrams(bigram_measures.pmi)\n",
    "# chi-square score\n",
    "ch = finder.score_ngrams(bigram_measures.chi_sq)\n",
    "# log-likelihood ratio\n",
    "log = finder.score_ngrams(bigram_measures.likelihood_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the results for the Log-likelihood test. The bigrams are sorted in order of significance, and the order of the words in the word-pairs shows their placement in the text. This means that the most significant bigram in the Log-likelihood test contained the words `digital privacy`, in that order. The word `digital` appears later on in the list with a lower score when it occurs after the word `privacy`. Scores above 3.8 are considered to be significant for the Log-likelihood test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('digital', 'privacy'), 1396.7176484665242), (('protect', 'privacy'), 215.8213968026119), (('privacy', 'ethic'), 155.35028599292028), (('access', 'privacy'), 126.05409003413976), (('privacy', 'right'), 93.24869199688817), (('privacy', 'protection'), 85.02469784716251), (('expectation', 'privacy'), 76.10335769327762), (('information', 'privacy'), 69.59199200288319), (('privacy', 'digital'), 56.657303415651356), (('protection', 'privacy'), 49.93335470726988), (('privacy', 'personal'), 48.402130602599286), (('respect', 'privacy'), 44.06965766960184), (('online', 'privacy'), 42.64245113742946), (('privacy', 'privacy'), 42.03746458118176), (('privacy', 'organization'), 39.70209960771831), (('sector', 'privacy'), 38.1170863577707), (('privacy', 'express'), 35.45600258359461), (('privacy', 'greatly'), 34.76347150169757), (('privacy', 'auditor'), 34.69326636806207), (('breach', 'privacy'), 27.595466396858995), (('right', 'privacy'), 25.095042430293038), (('give', 'privacy'), 24.839726930933214), (('privacy', 'principle'), 22.051400043024586), (('apply', 'privacy'), 20.994992843501095), (('enforce', 'privacy'), 19.92753679131834), (('power', 'privacy'), 19.526908996984915), (('violation', 'privacy'), 19.434755205509127), (('consult', 'privacy'), 17.652456219349105), (('privacy', 'information'), 16.245693706319194), (('privacy', 'strengthen'), 15.368625124563946), (('privacy', 'power'), 15.078256040500019), (('loss', 'privacy'), 14.81150348961551), (('privacy', 'law'), 14.792382455420682), (('privacy', 'legislation'), 14.303611440104474), (('security', 'privacy'), 12.767370201284859), (('privacy', 'appear'), 12.603176655580299), (('privacy', 'consult'), 12.460520468290241), (('ensure', 'privacy'), 11.979665416588306), (('data', 'privacy'), 11.906691234955007), (('privacy', 'practice'), 11.434462074381523), (('privacy', 'recommendation'), 11.34127749270883), (('review', 'privacy'), 10.770707188078871), (('strengthen', 'privacy'), 10.67289730252202), (('privacy', 'expert'), 10.312266608236044), (('former', 'privacy'), 9.936355596063862), (('privacy', 'human'), 9.866993102361253), (('privacy', 'establish'), 9.565553133513479), (('privacy', 'propose'), 9.27808391590139), (('safe', 'privacy'), 8.841902671255946), (('privacy', 'officer'), 8.798555471733122), (('balance', 'privacy'), 8.514290521370409), (('privacy', 'require'), 8.46405447117844), (('privacy', 'policy'), 8.204075736760359), (('privacy', 'seek'), 8.100588512517266), (('privacy', 'raise'), 6.740671373502669), (('report', 'privacy'), 6.197679497928247), (('regard', 'privacy'), 6.049419358110766), (('hear', 'privacy'), 5.51497706988944), (('privacy', 'respect'), 5.5018341665530395), (('individual', 'privacy'), 5.385100255074544), (('privacy', 'individual'), 5.385100255074544), (('current', 'privacy'), 5.084881474130804), (('concern', 'privacy'), 4.721989985307719), (('privacy', 'clear'), 4.473928611384574), (('privacy', 'allow'), 4.463299239945539), (('privacy', 'report'), 3.925829385855569), (('privacy', 'important'), 3.7855726127589433), (('privacy', 'provide'), 3.7669960974635996), (('privacy', 'need'), 3.249153293418055), (('privacy', 'come'), 3.2327843000729777), (('law', 'privacy'), 3.2224978586295903), (('privacy', 'protect'), 3.138874923948591), (('privacy', 'security'), 3.014157344038555), (('privacy', 'actually'), 2.8981179813812448), (('privacy', 'number'), 2.8189978649515686), (('privacy', 'concern'), 2.6166529202916093), (('allow', 'privacy'), 2.4341938920727513), (('privacy', 'give'), 2.4181122973951554), (('privacy', 'find'), 2.2324284944804758), (('change', 'privacy'), 2.046485912202238), (('talk', 'privacy'), 1.6516181058669535), (('privacy', 'business'), 1.4581067351683692), (('issue', 'privacy'), 0.9188763679430347), (('privacy', 'issue'), 0.9188763679430347), (('privacy', 'ensure'), 0.6038379234406515)]\n"
     ]
    }
   ],
   "source": [
    "print(log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display this data as a table, and remove some of the extra decimal digits. Using the tabulate module, we call the variable `log`, set the table heading names (displayed in red), and set the number of decimal digits to 3 (indicated by `floatfmt=\".3f\"`), with the numbers aligned on the leftmost digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collocate                      Log-Likelihood\n",
      "-----------------------------  ----------------\n",
      "('digital', 'privacy')         1396.718\n",
      "('protect', 'privacy')         215.821\n",
      "('privacy', 'ethic')           155.350\n",
      "('access', 'privacy')          126.054\n",
      "('privacy', 'right')           93.249\n",
      "('privacy', 'protection')      85.025\n",
      "('expectation', 'privacy')     76.103\n",
      "('information', 'privacy')     69.592\n",
      "('privacy', 'digital')         56.657\n",
      "('protection', 'privacy')      49.933\n",
      "('privacy', 'personal')        48.402\n",
      "('respect', 'privacy')         44.070\n",
      "('online', 'privacy')          42.642\n",
      "('privacy', 'privacy')         42.037\n",
      "('privacy', 'organization')    39.702\n",
      "('sector', 'privacy')          38.117\n",
      "('privacy', 'express')         35.456\n",
      "('privacy', 'greatly')         34.763\n",
      "('privacy', 'auditor')         34.693\n",
      "('breach', 'privacy')          27.595\n",
      "('right', 'privacy')           25.095\n",
      "('give', 'privacy')            24.840\n",
      "('privacy', 'principle')       22.051\n",
      "('apply', 'privacy')           20.995\n",
      "('enforce', 'privacy')         19.928\n",
      "('power', 'privacy')           19.527\n",
      "('violation', 'privacy')       19.435\n",
      "('consult', 'privacy')         17.652\n",
      "('privacy', 'information')     16.246\n",
      "('privacy', 'strengthen')      15.369\n",
      "('privacy', 'power')           15.078\n",
      "('loss', 'privacy')            14.812\n",
      "('privacy', 'law')             14.792\n",
      "('privacy', 'legislation')     14.304\n",
      "('security', 'privacy')        12.767\n",
      "('privacy', 'appear')          12.603\n",
      "('privacy', 'consult')         12.461\n",
      "('ensure', 'privacy')          11.980\n",
      "('data', 'privacy')            11.907\n",
      "('privacy', 'practice')        11.434\n",
      "('privacy', 'recommendation')  11.341\n",
      "('review', 'privacy')          10.771\n",
      "('strengthen', 'privacy')      10.673\n",
      "('privacy', 'expert')          10.312\n",
      "('former', 'privacy')          9.936\n",
      "('privacy', 'human')           9.867\n",
      "('privacy', 'establish')       9.566\n",
      "('privacy', 'propose')         9.278\n",
      "('safe', 'privacy')            8.842\n",
      "('privacy', 'officer')         8.799\n",
      "('balance', 'privacy')         8.514\n",
      "('privacy', 'require')         8.464\n",
      "('privacy', 'policy')          8.204\n",
      "('privacy', 'seek')            8.101\n",
      "('privacy', 'raise')           6.741\n",
      "('report', 'privacy')          6.198\n",
      "('regard', 'privacy')          6.049\n",
      "('hear', 'privacy')            5.515\n",
      "('privacy', 'respect')         5.502\n",
      "('individual', 'privacy')      5.385\n",
      "('privacy', 'individual')      5.385\n",
      "('current', 'privacy')         5.085\n",
      "('concern', 'privacy')         4.722\n",
      "('privacy', 'clear')           4.474\n",
      "('privacy', 'allow')           4.463\n",
      "('privacy', 'report')          3.926\n",
      "('privacy', 'important')       3.786\n",
      "('privacy', 'provide')         3.767\n",
      "('privacy', 'need')            3.249\n",
      "('privacy', 'come')            3.233\n",
      "('law', 'privacy')             3.222\n",
      "('privacy', 'protect')         3.139\n",
      "('privacy', 'security')        3.014\n",
      "('privacy', 'actually')        2.898\n",
      "('privacy', 'number')          2.819\n",
      "('privacy', 'concern')         2.617\n",
      "('allow', 'privacy')           2.434\n",
      "('privacy', 'give')            2.418\n",
      "('privacy', 'find')            2.232\n",
      "('change', 'privacy')          2.046\n",
      "('talk', 'privacy')            1.652\n",
      "('privacy', 'business')        1.458\n",
      "('issue', 'privacy')           0.919\n",
      "('privacy', 'issue')           0.919\n",
      "('privacy', 'ensure')          0.604\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(log, headers = [\"Collocate\", \"Log-Likelihood\"], floatfmt=\".3f\", numalign=\"left\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we print the results of this table to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('2015CompleteLog.csv','w') as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerows(log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the table above is nice, it isn't formated exactly the way it could be, especially since we already know that privacy is one half of the bigram. I want to format the list so I can do some further processing in some spreadsheet software, including combining the scores of the bigrams (like `digital privacy` and `privacy digital`) so I can have one score for each word.\n",
    "\n",
    "The code below sorts the lists generated by each test by the first word in the bigram, appending them to a dictionary called `prefix_keys`, where each word is a key and the score is the value. Then, we sort the keys by the value with the highest score, and assign the new list to a new variable where we obscure the keys containing the word `privacy`. This code must be repeated for each test. \n",
    "\n",
    "For the purposes of this analysis, we will only output the two frequency tests and the Log-likelihood test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##################################################################\n",
    "################ sorts list of ACTUAL frequencies ################\n",
    "##################################################################\n",
    "\n",
    "# group bigrams by first and second word in bigram                                        \n",
    "prefix_keys = collections.defaultdict(list)\n",
    "for key, a in act:\n",
    "    # first word\n",
    "    prefix_keys[key[0]].append((key[1], a))\n",
    "     # second word\n",
    "    prefix_keys[key[1]].append((key[0], a))\n",
    "    \n",
    "# sort keyed bigrams by strongest association.                                  \n",
    "for key in prefix_keys:\n",
    "    prefix_keys[key].sort(key = lambda x: -x[1])\n",
    "\n",
    "# remove the word privacy and display the first 50 results\n",
    "actkeys = prefix_keys['privacy'][:50]\n",
    "\n",
    "##################################################################\n",
    "#### sorts list of RAW (expressed as percentage) frequencies #####\n",
    "##################################################################\n",
    "\n",
    "# group bigrams by first and second word in bigram                                         \n",
    "prefix_keys = collections.defaultdict(list)\n",
    "for key, r in raw:\n",
    "    # first word\n",
    "    prefix_keys[key[0]].append((key[1], r))\n",
    "    # second word\n",
    "    prefix_keys[key[1]].append((key[0], r))\n",
    "    \n",
    "# sort keyed bigrams by strongest association.                                  \n",
    "for key in prefix_keys:\n",
    "    prefix_keys[key].sort(key = lambda x: -x[1])\n",
    "\n",
    "rawkeys = prefix_keys['privacy'][:50]\n",
    "\n",
    "##################################################################\n",
    "############### sorts list of log-likelihood scores ##############\n",
    "##################################################################\n",
    "\n",
    "# group bigrams by first and second word in bigram                                        \n",
    "prefix_keys = collections.defaultdict(list)\n",
    "for key, l in log:\n",
    "    # first word\n",
    "    prefix_keys[key[0]].append((key[1], l))\n",
    "    # second word\n",
    "    prefix_keys[key[1]].append((key[0], l))\n",
    "    \n",
    "# sort bigrams by strongest association                                  \n",
    "for key in prefix_keys:\n",
    "    prefix_keys[key].sort(key = lambda x: -x[1])\n",
    "\n",
    "logkeys = prefix_keys['privacy'][:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the new list of scores for the Log-likelihood test, with the word `privacy` removed. Nothing has changed here except the formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collocate       Log-Likelihood\n",
      "--------------  ----------------\n",
      "digital         1396.718\n",
      "protect         215.821\n",
      "ethic           155.350\n",
      "access          126.054\n",
      "right           93.249\n",
      "protection      85.025\n",
      "expectation     76.103\n",
      "information     69.592\n",
      "digital         56.657\n",
      "protection      49.933\n",
      "personal        48.402\n",
      "respect         44.070\n",
      "online          42.642\n",
      "privacy         42.037\n",
      "privacy         42.037\n",
      "organization    39.702\n",
      "sector          38.117\n",
      "express         35.456\n",
      "greatly         34.763\n",
      "auditor         34.693\n",
      "breach          27.595\n",
      "right           25.095\n",
      "give            24.840\n",
      "principle       22.051\n",
      "apply           20.995\n",
      "enforce         19.928\n",
      "power           19.527\n",
      "violation       19.435\n",
      "consult         17.652\n",
      "information     16.246\n",
      "strengthen      15.369\n",
      "power           15.078\n",
      "loss            14.812\n",
      "law             14.792\n",
      "legislation     14.304\n",
      "security        12.767\n",
      "appear          12.603\n",
      "consult         12.461\n",
      "ensure          11.980\n",
      "data            11.907\n",
      "practice        11.434\n",
      "recommendation  11.341\n",
      "review          10.771\n",
      "strengthen      10.673\n",
      "expert          10.312\n",
      "former          9.936\n",
      "human           9.867\n",
      "establish       9.566\n",
      "propose         9.278\n",
      "safe            8.842\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "print(tabulate(logkeys, headers = [\"Collocate\", \"Log-Likelihood\"], floatfmt=\".3f\", numalign=\"left\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, just for reference, these are the 25 top Log-Likelhood scores for 2015 without the stopwords applied."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Collocate     Log-Likelihood\n",
    "------------  ----------------\n",
    "commissioner  2526.639692684\n",
    "digital       1645.943598842\n",
    "the           778.568954598\n",
    "act           600.684800536\n",
    "and           117.297111827\n",
    "right         107.573441279\n",
    "protection    94.322301426\n",
    "their         62.085308377\n",
    "protect       58.045722275\n",
    "online        57.526177072\n",
    "sector        51.091917412\n",
    "interim       40.912165767\n",
    "to            36.187103272\n",
    "law           30.168200789\n",
    "the           29.228587343\n",
    "of            27.547037820\n",
    "which         22.595494211\n",
    "practice      21.302055792\n",
    "daniel        20.643040763\n",
    "strengthen    18.703927899\n",
    "expert        18.313791177\n",
    "a             18.065369736\n",
    "legislation   14.152985001\n",
    "policy        12.467935832\n",
    "current       12.367826207"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will write the sorted results of the tests to a CSV file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('2015collocate_Act.csv','w') as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerows(actkeys)\n",
    "\n",
    "with open('2015collocate_Raw.csv','w') as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerows(rawkeys)\n",
    "    \n",
    "with open('2015collocate_Log.csv','w') as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerows(logkeys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is immediately apparent from the Log-likelihood scores is that there are distinct types of words that co-occur with the word privacy. The top 10 most frequently co-occuring words are digital, protect, ethic, access, right, protection, expectation, and information. Based on this list alone, we can deduce that privacy in the Hansard corpus is a serious topic; one that is concerned with ethics and rights, which are things commonly associated with the law. We can also see that privacy has both a digital and an informational aspect, which are things that have an expectation of both access and protection. \n",
    "\n",
    "While it may seem obvious that these kinds of words would co-occur with privacy, we now have statistical evidence upon which to build our claim. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Reading the whole corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we repeat the above code, only instead of using one file, we will combine all of the files to obtain the scores for the entire corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for filename in list_textfiles('data'):\n",
    "    text_2 = read_file(filename)\n",
    "    words_2 = text_2.split()\n",
    "    clean_2 = [w.lower() for w in words_2 if w.isalpha()]\n",
    "    text_2 = [w for w in clean_2 if w not in hansardStopwords]\n",
    "    corpus.append(text_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lemm_2 = []\n",
    "for doc in corpus:\n",
    "    for word in doc:\n",
    "        lemm_2.append(wnl.lemmatize(word, 'v'))\n",
    "lems_2 = []\n",
    "for word in lemm_2:\n",
    "    lems_2.append(wnl.lemmatize(word, 'n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "employment insurance; free trade; human right; criminal code; unite\n",
      "state; foreign affair; greenhouse gas; supreme court; economic\n",
      "development; health care\n"
     ]
    }
   ],
   "source": [
    "# prints the 10 most common multi-word pairs (n-grams)\n",
    "colText_2 = nltk.Text(lems_2)\n",
    "colText_2.collocations(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# bigrams\n",
    "finder_2 = BigramCollocationFinder.from_words(lems_2)\n",
    "# only bigrams that appear 4+ times\n",
    "finder_2.apply_freq_filter(4)\n",
    "# only bigrams that contain 'privacy'\n",
    "finder_2.apply_ngram_filter(privacy_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filter results based on statistical test\n",
    "act_2 = finder_2.ngram_fd.items()\n",
    "raw_2 = finder_2.score_ngrams(bigram_measures.raw_freq)\n",
    "log_2 = finder_2.score_ngrams(bigram_measures.likelihood_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##################################################################\n",
    "################ sorts list of ACTUAL frequencies ################\n",
    "##################################################################\n",
    "\n",
    "# group bigrams by first and second word in bigram                                        \n",
    "prefix_keys = collections.defaultdict(list)\n",
    "for key, a in act_2:\n",
    "    # first word\n",
    "    prefix_keys[key[0]].append((key[1], a))\n",
    "     # second word\n",
    "    prefix_keys[key[1]].append((key[0], a))\n",
    "    \n",
    "# sort keyed bigrams by strongest association.                                  \n",
    "for key in prefix_keys:\n",
    "    prefix_keys[key].sort(key = lambda x: -x[1])\n",
    "\n",
    "# remove the word privacy and display the first 50 results\n",
    "actkeys_2 = prefix_keys['privacy'][:50]\n",
    "\n",
    "##################################################################\n",
    "#### sorts list of RAW (expressed as percentage) frequencies #####\n",
    "##################################################################\n",
    "\n",
    "# group bigrams by first and second word in bigram                                         \n",
    "prefix_keys = collections.defaultdict(list)\n",
    "for key, r in raw_2:\n",
    "    # first word\n",
    "    prefix_keys[key[0]].append((key[1], r))\n",
    "    # second word\n",
    "    prefix_keys[key[1]].append((key[0], r))\n",
    "    \n",
    "# sort keyed bigrams by strongest association.                                  \n",
    "for key in prefix_keys:\n",
    "    prefix_keys[key].sort(key = lambda x: -x[1])\n",
    "\n",
    "rawkeys_2 = prefix_keys['privacy'][:50]\n",
    "\n",
    "##################################################################\n",
    "############### sorts list of log-likelihood scores ##############\n",
    "##################################################################\n",
    "\n",
    "# group bigrams by first and second word in bigram                                        \n",
    "prefix_keys = collections.defaultdict(list)\n",
    "for key, l in log_2:\n",
    "    # first word\n",
    "    prefix_keys[key[0]].append((key[1], l))\n",
    "    # second word\n",
    "    prefix_keys[key[1]].append((key[0], l))\n",
    "    \n",
    "# sort bigrams by strongest association                                  \n",
    "for key in prefix_keys:\n",
    "    prefix_keys[key].sort(key = lambda x: -x[1])\n",
    "\n",
    "logkeys_2 = prefix_keys['privacy'][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collocate        Log-Likelihood\n",
      "---------------  ----------------\n",
      "access           5110.393\n",
      "ethic            5107.996\n",
      "digital          1920.924\n",
      "protect          1839.608\n",
      "right            1229.061\n",
      "information      1062.382\n",
      "invasion         904.061\n",
      "privacy          553.362\n",
      "privacy          553.362\n",
      "protection       476.078\n",
      "breach           444.387\n",
      "breach           376.297\n",
      "respect          350.245\n",
      "right            349.423\n",
      "personal         345.511\n",
      "violation        313.199\n",
      "violate          306.068\n",
      "protection       275.448\n",
      "personal         253.184\n",
      "invade           246.280\n",
      "expectation      237.897\n",
      "concern          215.959\n",
      "issue            207.534\n",
      "law              204.353\n",
      "information      192.077\n",
      "ensure           190.866\n",
      "concern          174.224\n",
      "online           135.406\n",
      "competition      129.990\n",
      "intrude          110.100\n",
      "civil            108.547\n",
      "csec             100.214\n",
      "balance          98.426\n",
      "confidentiality  90.763\n",
      "digital          90.598\n",
      "safeguard        89.725\n",
      "intrusion        84.955\n",
      "routine          78.433\n",
      "access           75.575\n",
      "report           73.453\n",
      "individual       69.919\n",
      "protect          67.792\n",
      "security         64.219\n",
      "waiver           63.776\n",
      "infringe         63.697\n",
      "expert           62.525\n",
      "honour           62.467\n",
      "interest         61.506\n",
      "compromise       60.703\n",
      "liberty          56.292\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "print(tabulate(logkeys_2, headers = [\"Collocate\", \"Log-Likelihood\"], floatfmt=\".3f\", numalign=\"left\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('Allcollocate_Act.csv','w') as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerows(actkeys_2)\n",
    "\n",
    "with open('Allcollocate_Raw.csv','w') as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerows(rawkeys_2)\n",
    "    \n",
    "with open('Allcollocate_Log.csv','w') as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerows(logkeys_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The processed spreadsheet including the cumulative scores for all the bigrams for each test for every year and Parliament can be accessed here: <a href=\"HansardCollocationTable.xlsx\" target=blank>Hansard Collocation Table</a>. If you plan to use the data, please cite appropriately."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
